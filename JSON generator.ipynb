{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a9c2e0",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook initialises functions which can be used for generation of independent data. The other powerful methods in this repo generate synthetic data based on an already existing dataset. This notebook includes functions which take in user inputs which could easily be ported into an app and by simply using different prompts, a lot of features could be added.\n",
    "\n",
    "Types of data, features and how to randomize choosing them:\n",
    "\n",
    "* Integer: min/max, distribution, specific probabilities (weighted random)\n",
    "* Float: min/max, distribution, specific probabilities (weighted random)\n",
    "* categorical (types) : specific probabilities (weighted random), pseudo random (coin toss)\n",
    "* dates/timestamps: start date/end date, amount per day, amount at specific times\n",
    "* Boolean : specific probabilities (weighted random), pseudo random (coin toss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fffb51",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcded81d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b8047b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T08:16:10.641418Z",
     "start_time": "2021-07-23T08:16:10.016395Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4ef41",
   "metadata": {},
   "source": [
    "## Distribution generator\n",
    "\n",
    "This randomizer takes in input for the paramaters depending on the distribution selected. It also accepts min and max arguments for the output of the data set in a 'data smapling' method similar to SDV's \"reject_sampling\" method. Thanks to numpy's extremely efficient array creator, the sampling method used barely takes more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5953871b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:56.027695Z",
     "start_time": "2021-07-23T09:21:55.954700Z"
    },
    "code_folding": [
     18,
     31,
     43,
     50,
     57,
     67,
     75,
     83,
     91,
     92,
     103,
     115,
     132,
     140,
     148,
     156,
     164,
     172,
     189,
     202,
     215,
     227,
     239
    ]
   },
   "outputs": [],
   "source": [
    "def Randomizer(object_name, distribution, size):\n",
    "    new_data = np.array([])\n",
    "\n",
    "    # Takes in min and max but if none are required or weighted distribution is requested on \n",
    "    # Categorical Data, the input can be 'None' and no sampling will be done\n",
    "    MIN = float(\n",
    "        input('Input the minimum value of the data of object \\\"' +\n",
    "              object_name + '\\\", if not applicable type \\'None\\':'))\n",
    "    MAX = float(\n",
    "        input('Input the maximum value of the data of object \\\"' +\n",
    "              object_name + '\\\", if not applicable type \\'None\\':'))\n",
    "    \n",
    "    # if Min  is greater than max the sampler will always empty the array and this will loop without end\n",
    "    if MIN > MAX:\n",
    "        warnings.warn('Minimum is higher than maximum!')  \n",
    "        return None\n",
    "\n",
    "    while len(new_data) < size: # Distribution generation loop\n",
    "        if (distribution == 'Normal'):\n",
    "            if len(new_data) < 1:\n",
    "                mean = float(\n",
    "                    input(\n",
    "                        'Input mean value for Normal distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                std = float(\n",
    "                    input(\n",
    "                        'Input standard deviation value for Uniform distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            # Plan on adding possibility of inserting a df with column specified or list input possibility to find mena/std\n",
    "            new_data = np.append(new_data, np.random.normal(mean, std, size))\n",
    "\n",
    "        elif (distribution == 'Uniform'):\n",
    "            if len(new_data) < 1:\n",
    "                Min = float(\n",
    "                    input(\n",
    "                        'Input a value for Uniform distribution of object \\\"' +\n",
    "                        object_name + '\\\":'))\n",
    "                Max = float(\n",
    "                    input(\n",
    "                        'Input b value for Uniform distribution of object \\\"' +\n",
    "                        object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.uniform(Min, Max, size))\n",
    "\n",
    "        elif (distribution == 'Gamma'):\n",
    "            if len(new_data) < 1:\n",
    "                a = float(\n",
    "                    input('Input a value for Gamma distribution of object \\\"' +\n",
    "                          object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, gamma.rvs(a, size))\n",
    "\n",
    "        elif (distribution == 'Exponential'):\n",
    "            if len(new_data) < 1:\n",
    "                a = float(\n",
    "                    input('Input rate parameter of object \\\"' + object_name +\n",
    "                          '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.exponential(a, size))\n",
    "\n",
    "        elif (distribution == 'Weighted Distribution'):\n",
    "            if len(new_data) < 1:\n",
    "                val = input('Input array of values of object \\\"' +\n",
    "                            object_name + '\\\":').split(',')\n",
    "                weights = input(\n",
    "                    'Input array of weights for the values of object \\\"' +\n",
    "                    object_name + '\\\":').split(',').astype(float)\n",
    "            new_data = np.append(new_data,\n",
    "                                 np.random.choice(val, size=size, p=weights))\n",
    "\n",
    "        elif (distribution == 'Weibull'):\n",
    "            if len(new_data) < 1:\n",
    "                a = float(\n",
    "                    input(\n",
    "                        'Input shape value for Weibull distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.weibull(a, size))\n",
    "\n",
    "        elif (distribution == 'Poisson'):\n",
    "            if len(new_data) < 1:\n",
    "                lam = float(\n",
    "                    input(\n",
    "                        'Input expected number for Poisson distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.poisson(lam, size))\n",
    "\n",
    "        elif (distribution == 'Zipf'):\n",
    "            if len(new_data) < 1:\n",
    "                a = float(\n",
    "                    input(\n",
    "                        'Input parameter value for zipf distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.zipf(a, size))\n",
    "\n",
    "        elif (distribution == 'Wald'):\n",
    "            if len(new_data) < 1:\n",
    "                mean = float(\n",
    "                    input(\n",
    "                        'Input mean value for wald distribution of object \\\"' +\n",
    "                        object_name + '\\\":'))\n",
    "                scale = float(\n",
    "                    input(\n",
    "                        'Input scale value for wald distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.wald(mean, scale, size))\n",
    "\n",
    "        elif (distribution == 'Vonmises'):\n",
    "            if len(new_data) < 1:\n",
    "                mu = float(\n",
    "                    input(\n",
    "                        'Input mu value for vonmises distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                kappa = float(\n",
    "                    input(\n",
    "                        'Input kappa value for vonmises distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.vonmises(mu, kappa, size))\n",
    "\n",
    "        elif (distribution == 'Triangular'):\n",
    "            if len(new_data) < 1:\n",
    "                left = float(\n",
    "                    input(\n",
    "                        'Input left value for Triangular distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                mode = float(\n",
    "                    input(\n",
    "                        'Input mode value for Triangular distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                right = float(\n",
    "                    input(\n",
    "                        'Input right value for Triangular distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data,\n",
    "                                 np.random.triangular(left, mode, right, size))\n",
    "\n",
    "        elif (distribution == 'Standard T'):\n",
    "            if len(new_data) < 1:\n",
    "                df = float(\n",
    "                    input(\n",
    "                        'Input degrees of freedom value for standard_t distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.standard_t(df, size))\n",
    "\n",
    "        elif (distribution == 'Rayleigh'):\n",
    "            if len(new_data) < 1:\n",
    "                scale = float(\n",
    "                    input(\n",
    "                        'Input scale value for rayleigh distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.rayleigh(scale, size))\n",
    "\n",
    "        elif (distribution == 'Power'):\n",
    "            if len(new_data) < 1:\n",
    "                a = float(\n",
    "                    input(\n",
    "                        'Input paramater value for power distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.power(a, size))\n",
    "\n",
    "        elif (distribution == 'Poisson'):\n",
    "            if len(new_data) < 1:\n",
    "                lam = float(\n",
    "                    input(\n",
    "                        'Input lamda value for Poisson distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.poisson(lam, size))\n",
    "\n",
    "        elif (distribution == 'Pareto'):\n",
    "            if len(new_data) < 1:\n",
    "                lam = float(\n",
    "                    input(\n",
    "                        'Input lamda value for Pareto distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.pareto(lam, size))\n",
    "\n",
    "        elif (distribution == 'Noncentral F'):\n",
    "            if len(new_data) < 1:\n",
    "                dfnum = float(\n",
    "                    input(\n",
    "                        'Input Numerator degrees of freedom value for Noncentral F distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                dfden = float(\n",
    "                    input(\n",
    "                        'Input Denominator degrees of freedom value for Noncentral F distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                nonc = float(\n",
    "                    input(\n",
    "                        'Input non-centrality value for Noncentral F distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(\n",
    "                new_data, np.random.noncentral_f(dfnum, dfden, nonc, size))\n",
    "\n",
    "        elif (distribution == 'Noncentral Chisquare'):\n",
    "            if len(new_data) < 1:\n",
    "                df = float(\n",
    "                    input(\n",
    "                        'Input degrees of freedom value for Noncentral Chisquare distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                nonc = float(\n",
    "                    input(\n",
    "                        'Input non-centrality value for Normal distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(\n",
    "                new_data, np.random.noncentral_chisquare(df, nonc, size))\n",
    "\n",
    "        elif (distribution == 'Logistic'):\n",
    "            if len(new_data) < 1:\n",
    "                loc = float(\n",
    "                    input(\n",
    "                        'Input loc value for logistic distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                scale = float(\n",
    "                    input(\n",
    "                        'Input scale value for logistic distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data,\n",
    "                                 np.random.logistic(loc, scale, size))\n",
    "\n",
    "        elif (distribution == 'Laplace'):\n",
    "            if len(new_data) < 1:\n",
    "                loc = float(\n",
    "                    input(\n",
    "                        'Input loc value for Laplace distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                scale = float(\n",
    "                    input(\n",
    "                        'Input scale value for Laplace distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.laplace(loc, scale, size))\n",
    "\n",
    "        elif (distribution == 'Gumbel'):\n",
    "            if len(new_data) < 1:\n",
    "                loc = float(\n",
    "                    input(\n",
    "                        'Input loc value for gumbel distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "                scale = float(\n",
    "                    input(\n",
    "                        'Input scale value for gumbel distribution of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.appendd(new_data, np.random.gumbel(loc, scale, size))\n",
    "\n",
    "        elif (distribution == 'Chisquare'):\n",
    "            if len(new_data) < 1:\n",
    "                df = float(\n",
    "                    input(\n",
    "                        'Input degrees of freedom value for Normal Chisquare of object \\\"'\n",
    "                        + object_name + '\\\":'))\n",
    "            new_data = np.append(new_data, np.random.chisquare(df, size))\n",
    "\n",
    "        if MAX != 'None': # Sampler removing values greater than max then smaller than min \n",
    "            new_data = new_data[new_data < MAX]\n",
    "        if MIN != 'None':\n",
    "            new_data = new_data[new_data > MIN]\n",
    "    return new_data[:size] # selects requested size of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ec4c4",
   "metadata": {},
   "source": [
    "## Feature generation by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c8ef3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:57.173008Z",
     "start_time": "2021-07-23T09:21:57.168009Z"
    }
   },
   "outputs": [],
   "source": [
    "def IntegerGenerator(object_name, distribution, size):\n",
    "    # Calls the randomizer outputting a pandas df of type int\n",
    "    int_Array = Randomizer(object_name, distribution, size).astype(int)\n",
    "    objectslice = pd.DataFrame(data=int_Array, columns=[object_name])\n",
    "    return objectslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549e7172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:57.502968Z",
     "start_time": "2021-07-23T09:21:57.488972Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def FloatGenerator(object_name, distribution, size):\n",
    "    # Calls the randomizer outputting a pandas df of type float\n",
    "    float_Array = Randomizer(object_name, distribution, size).astype(float)\n",
    "    objectslice = pd.DataFrame(data=float_Array, columns=[object_name])\n",
    "    return objectslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54e0dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:57.897375Z",
     "start_time": "2021-07-23T09:21:57.888376Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def CategoricalData(object_name, randomization_type, size):\n",
    "    # Calls the randomizer or randomizes without distribution outputting a pandas df for categorical data\n",
    "    if randomization_type == 'Weighted Distribution':\n",
    "        cat_arr = Randomizer(object_name, randomization_type, size)\n",
    "        objectslice = pd.DataFrame(data=cat_arr, columns=[object_name])\n",
    "    elif randomization_type == 'Random':\n",
    "        val = input('Input array of values of object \\\"' + object_name +\n",
    "                    '\\\":').split(',')\n",
    "        new_data = np.random.choice(val, size=size)\n",
    "        objectslice = pd.DataFrame(data=new_data, columns=[object_name])\n",
    "    return objectslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be35bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:58.365373Z",
     "start_time": "2021-07-23T09:21:58.353375Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def TimestampGenerator(object_name,\n",
    "                       start=None,\n",
    "                       end=None,\n",
    "                       periods=None,\n",
    "                       frequency=None):\n",
    "    # receives timestamp specifications and creates and outputs a pandas df of type timestamp\n",
    "    objectslice = pd.DataFrame(pd.date_range(start=start,\n",
    "                                             end=end,\n",
    "                                             periods=periods,\n",
    "                                             freq=frequency,\n",
    "                                             name=object_name).to_pydatetime(),\n",
    "                               columns=[object_name])\n",
    "    return objectslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7cb3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:59.545111Z",
     "start_time": "2021-07-23T09:21:59.536113Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def BooleanGenerator(object_name, randomization_type, size):\n",
    "    # Calls the randomizer or randomizes without distribution outputting a pandas df for boolean data\n",
    "    val = [True, False]\n",
    "    if randomization_type == 'Weighted Distribution':\n",
    "        cat_arr = Randomizer(object_name, randomization_type, size)\n",
    "        objectslice = pd.DataFrame(data=cat_arr, columns=[object_name])\n",
    "    elif randomization_type == 'Random':\n",
    "        new_data = np.random.choice(val, size=size)\n",
    "        objectslice = pd.DataFrame(data=new_data, columns=[object_name])\n",
    "    return objectslice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c7e4f",
   "metadata": {},
   "source": [
    "# Dataframe Creation Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00a8d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T11:07:45.281813Z",
     "start_time": "2021-07-26T11:07:45.052773Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimestampGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16052/234954377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m timestamps = TimestampGenerator('time', '12/10/2021', '04/11/2030',\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 periods = size)\n\u001b[0;32m      4\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Item'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Random'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFloatGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TimestampGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "size = 1000\n",
    "timestamps = TimestampGenerator('time', '12/10/2021', '04/11/2030',\n",
    "                                periods = size)\n",
    "items = CategoricalData('Item', 'Random', size)\n",
    "values = FloatGenerator('Value', 'Normal', size)\n",
    "ratings = IntegerGenerator('Rating', 'Uniform', size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b795c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T12:36:29.064441Z",
     "start_time": "2021-07-16T12:36:29.064441Z"
    }
   },
   "source": [
    "table, chair, desk, chair, computer, window, book, emblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad5820",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:34.577Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([timestamps, items, values, ratings],\n",
    "                 ignore_index=True,\n",
    "                 axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300c119",
   "metadata": {},
   "source": [
    "# Data creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69c1e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T09:21:49.901801Z",
     "start_time": "2021-07-23T09:21:49.874799Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Calls must be lists in order desired\n",
    "# Features_names is a must strings\n",
    "# Features types has to be Timestamp, Categorical, Float or Integer\n",
    "# Distribution are the available distribution in randomizer + 'Random'. Takes input for timestamp but placeholder required\n",
    "# Size is an integer\n",
    "\n",
    "\n",
    "def DataGenerator(feature_names, features_type, distributions):\n",
    "    values_ = pd.DataFrame()\n",
    "    size = 0  # initialised for case when timestamp is not called first.\n",
    "    dispatcher = {\n",
    "        'Timestamp': TimestampGenerator,\n",
    "        'Categorical': CategoricalData,\n",
    "        'Float': FloatGenerator,\n",
    "        'Integer': IntegerGenerator\n",
    "    }  # enables function to be called from input\n",
    "\n",
    "    if len(feature_names) != len(features_type) or len(feature_names) != len(\n",
    "            distributions):\n",
    "        warnings.error(\n",
    "            'Not the same number of names, types and distributions!')\n",
    "        return None\n",
    "\n",
    "    for i in range(len(feature_names)):\n",
    "        # Accepts input for timestamp to define the size of the df\n",
    "        if features_type[i] == 'Timestamp':\n",
    "            print(\n",
    "                'Exactly 3 of the following inputs must be filled in, this will be responsible for the amount of messages created.'\n",
    "            )\n",
    "            # the pd.data_range accepts only 3 inputs of the 4 variables available, this creates a size of the array as specified\n",
    "            start = input('Input start date for \\\"' + feature_names[i] +\n",
    "                          '\\\", if not applicable type \\'None\\':')\n",
    "            end = input('Input end date for \\\"' + feature_names[i] +\n",
    "                        '\\\", if not applicable type \\'None\\':')\n",
    "            size = int(\n",
    "                input('Input the number of messages for \\\"' +\n",
    "                      feature_names[i] +\n",
    "                      '\\\", if not applicable type \\'None\\':'))\n",
    "            frequency = input('Input the frequency of messages for \\\"' +\n",
    "                              feature_names[i] +\n",
    "                              '\\\", if not applicable type \\'None\\':')\n",
    "            # For each case the dispatcher calls the timestamp function on the available variables and adds the new df column\n",
    "            # created to the complete dataset, values_\n",
    "            if start == 'None':\n",
    "                values_ = pd.concat([\n",
    "                    values_, dispatcher[features_type[i]](feature_names[i],\n",
    "                                                          end=end,\n",
    "                                                          periods=size,\n",
    "                                                          frequency=frequency)\n",
    "                ],\n",
    "                                    ignore_index=True,\n",
    "                                    axis=1)\n",
    "            elif end == 'None':\n",
    "                values_ = pd.concat([\n",
    "                    values_, dispatcher[features_type[i]](feature_names[i],\n",
    "                                                          start=start,\n",
    "                                                          periods=size,\n",
    "                                                          frequency=frequency)\n",
    "                ],\n",
    "                                    ignore_index=True,\n",
    "                                    axis=1)\n",
    "            elif frequency == 'None':\n",
    "                values_ = pd.concat([\n",
    "                    values_, dispatcher[features_type[i]](\n",
    "                        feature_names[i], start=start, periods=size, end=end)\n",
    "                ],\n",
    "                                    ignore_index=True,\n",
    "                                    axis=1)\n",
    "            elif size == 'None':\n",
    "                values_ = pd.concat([\n",
    "                    values_, dispatcher[features_type[i]](feature_names[i],\n",
    "                                                          start=start,\n",
    "                                                          end=end,\n",
    "                                                          frequency=frequency)\n",
    "                ],\n",
    "                                    ignore_index=True,\n",
    "                                    axis=1)\n",
    "                size = len(values_[i])\n",
    "                \n",
    "        # This is used to call all other functions but TimestampGenerator \n",
    "        else:\n",
    "            if size == 0:\n",
    "                size = input('Input size desired: ')\n",
    "            values_ = pd.concat([\n",
    "                values_, dispatcher[features_type[i]](feature_names[i],\n",
    "                                                      distributions[i], size)\n",
    "            ],\n",
    "                                ignore_index=True,\n",
    "                                axis=1)\n",
    "    values_.columns = feature_names\n",
    "    return values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4df9d7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T09:22:02.909Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactly 3 of the following inputs must be filled in, this will be responsible for the amount of messages created.\n"
     ]
    }
   ],
   "source": [
    "features = ['time','item', 'method', 'value', 'score', 'rating']\n",
    "ftype = ['Timestamp', 'Categorical', 'Categorical', 'Integer', 'Float', 'Float']\n",
    "distribution = ['N/A', 'Random', 'Random', 'Exponential', 'Normal', 'Uniform']\n",
    "\n",
    "final_data = DataGenerator(features, ftype, distribution)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b3226",
   "metadata": {},
   "source": [
    "# Generating telemetric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f139ea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T09:23:42.190Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['Timestamp','x1', 'y1', 'x2', 'y2', 'classes', 'scores']\n",
    "ftype = ['Timestamp', 'Float', 'Float', 'Float', 'Float', 'Categorical', 'Float']\n",
    "distribution = ['N/A', 'Normal', 'Normal', 'Normal', 'Normal', 'Random', 'Normal']\n",
    "\n",
    "telemetric = DataGenerator(features, ftype, distribution)\n",
    "telemetric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af3fef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:35.121Z"
    }
   },
   "outputs": [],
   "source": [
    "def box_format(df): # completely dependent on data, this just joins 4 columns to one with the string [a,b,c,d] \n",
    "    temp = []\n",
    "    new = pd.DataFrame()\n",
    "    new = df.copy()\n",
    "    for i in range(len(df.x1.tolist())):\n",
    "        temp.append('[' + str(df.x1.tolist()[i]) + ', ' +\n",
    "                    str(df.y1.tolist()[i]) + ', ' + str(df.x2.tolist()[i]) +\n",
    "                    ', ' + str(df.y2.tolist()[i]) + ']')\n",
    "    new.insert(1, 'sensors.video.boxes', temp)\n",
    "    new.drop(columns=['x1', 'y1', 'x2', 'y2'], inplace=True)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a1b79",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:35.159Z"
    }
   },
   "outputs": [],
   "source": [
    "telemetric_boxed = box_format(telemetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85089342",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:35.185Z"
    }
   },
   "outputs": [],
   "source": [
    "telemetric_boxed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f897e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:35.221Z"
    }
   },
   "outputs": [],
   "source": [
    "telemetric_json = telemetric_boxed.to_json(orient='values', date_format='iso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38296e23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T08:05:35.254Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('data/generated_telemetricdata.json', 'w')\n",
    "file.write(telemetric_json)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28a530",
   "metadata": {},
   "source": [
    "# Additional comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc96fb",
   "metadata": {},
   "source": [
    "As mentioned in the description, these functions could serve as the backend of a lot of feature functionality within an app. Maxime's main desrire for the customization aspect of data generation has been an example where a user could ask there to be fewer items at certain points in the day compared to others. \n",
    "\n",
    "An ineficient, but functional, way of accomplishing this would be to have the user input (the same way they did for the rest of the data) their desired timeframes and amounts of messages, and then call the _dataGenerator_ function seperately for the different timeframes ie. they ask for 1000 messages an hour between 9am and 6pm but 100 between 6pm and 9am, we can use the data generator for 9am to 6pm with the requested distribution etc and then use it again between 6pm and 9am but with a lower frequency and merge the datasets together. Moreover, if this was on a longer time frame such as 1 week where they also requested the 9am to 6pm requirement; we could simply make two datasets on that week with different amounts of messages per hour, then select the 9am to 6pm and 6pm to 9am slices and merge them. These brute force approaches would require the exact same inputs from the user as more sophisticated algorithms but would likely take longer.\n",
    "\n",
    "**Note** frequency specification business hours can be inluded which helps exclude weekends\n",
    "\n",
    "Another potential use case would be a never ending message generator which adds a message every determined amount of time. This could also be added as a functionality with simple use of python's integrated time function but needs to be investigated further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53246ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "190px",
    "width": "224px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
